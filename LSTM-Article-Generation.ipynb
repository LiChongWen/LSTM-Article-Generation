{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fImaxgRIjuCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15c58379-92b1-473b-93c4-493e6ec2c89c"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMsZvshh-raY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4739460a-710f-4e7c-c446-ca22d169643b"
      },
      "source": [
        "!wget --show-progress --continue -O /content/shakespeare.txt http://www.gutenberg.org/files/100/100-0.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-26 18:48:11--  http://www.gutenberg.org/files/100/100-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5777367 (5.5M) [text/plain]\n",
            "Saving to: ‘/content/shakespeare.txt’\n",
            "\n",
            "/content/shakespear 100%[===================>]   5.51M  5.37MB/s    in 1.0s    \n",
            "\n",
            "2020-03-26 18:48:17 (5.37 MB/s) - ‘/content/shakespeare.txt’ saved [5777367/5777367]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vPf3H_PajRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "b06bee63-ec9b-4138-baa7-9e585f75c199"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx3L39iCa5fi"
      },
      "source": [
        "TEST_FILE = '/content/test.txt'\n",
        "SHAKESPEARE_TXT = '/content/shakespeare.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQnTOjR9bUUR"
      },
      "source": [
        "def transfor(txt):\n",
        "  return np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDdFyLyfb6rm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2353c4f6-c3da-40aa-b9b4-b9c76b130a3f"
      },
      "source": [
        "with tf.io.gfile.GFile(TEST_FILE, 'r') as f:\n",
        "  txt = f.read()\n",
        "transfor(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 73, 116,  32, 105, 115,  32,  97,  32,  98, 101,  97, 117, 116,\n",
              "       105, 102, 117, 108,  32, 100,  97, 121,  44,  32, 114, 105, 103,\n",
              "       104, 116,  63,  32,  10,  76, 101, 116,  39, 115,  32, 103, 111,\n",
              "        32, 111, 117, 116,  32,  97, 110, 100,  32, 104,  97, 118, 101,\n",
              "        32, 102, 117, 110,  33], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlKKA1Z0brhF"
      },
      "source": [
        "#each input_size(sentence 字母数量) = seq_len, \n",
        "#每个batch 中 有 batch_size个 (input->target)的sets\n",
        "@tf.function\n",
        "def input_fn(seq_len=10, batch_size=2):\n",
        "  with tf.io.gfile.GFile(TEST_FILE, 'r') as f:\n",
        "    txt = f.read()\n",
        "  \n",
        "  source = tf.constant(transfor(txt), dtype=tf.int32)\n",
        "  #把tensor类型转化为dataset类型\n",
        "  ds = tf.data.Dataset.from_tensor_slices(source)\n",
        "  #Split the txt into sentenes, each sentences have seq_len+1 characters\n",
        "  ds = ds.batch(seq_len+1, True)\n",
        "  return ds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5BgzaoEey30"
      },
      "source": [
        "#make every sentences into:\n",
        "#   input sentence(first character to last-1 character)\n",
        "#   target_sentence(second char to last character)\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "BUFFER_SIZE = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLYEpr4ahAH1"
      },
      "source": [
        "ds = input_fn()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W9QMouahmo7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3f2f6e24-f1dc-4f54-bae6-607c4be4d4e9"
      },
      "source": [
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 73, 116,  32, 105, 115,  32,  97,  32,  98, 101,  97], dtype=int32),\n",
              " array([117, 116, 105, 102, 117, 108,  32, 100,  97, 121,  44], dtype=int32),\n",
              " array([ 32, 114, 105, 103, 104, 116,  63,  32,  10,  76, 101], dtype=int32),\n",
              " array([116,  39, 115,  32, 103, 111,  32, 111, 117, 116,  32], dtype=int32),\n",
              " array([ 97, 110, 100,  32, 104,  97, 118, 101,  32, 102, 117], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueejWvMrscrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7908f1b-10aa-41bb-9f9e-6796924adfac"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_VariantDataset shapes: (11,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-A45HIZhfRu"
      },
      "source": [
        "ds = ds.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbVkdJrNBXyx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6095e2cb-8d4a-4f7d-fc74-758056f47bec"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((10,), (10,)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4WPvuKhmUK1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b647ebf8-9295-4fc0-9081-fbf3504b1364"
      },
      "source": [
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([ 73, 116,  32, 105, 115,  32,  97,  32,  98, 101], dtype=int32),\n",
              "  array([116,  32, 105, 115,  32,  97,  32,  98, 101,  97], dtype=int32)),\n",
              " (array([117, 116, 105, 102, 117, 108,  32, 100,  97, 121], dtype=int32),\n",
              "  array([116, 105, 102, 117, 108,  32, 100,  97, 121,  44], dtype=int32)),\n",
              " (array([ 32, 114, 105, 103, 104, 116,  63,  32,  10,  76], dtype=int32),\n",
              "  array([114, 105, 103, 104, 116,  63,  32,  10,  76, 101], dtype=int32)),\n",
              " (array([116,  39, 115,  32, 103, 111,  32, 111, 117, 116], dtype=int32),\n",
              "  array([ 39, 115,  32, 103, 111,  32, 111, 117, 116,  32], dtype=int32)),\n",
              " (array([ 97, 110, 100,  32, 104,  97, 118, 101,  32, 102], dtype=int32),\n",
              "  array([110, 100,  32, 104,  97, 118, 101,  32, 102, 117], dtype=int32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkekG9aLmnm1"
      },
      "source": [
        "#Shuffle the (input->target) sets\n",
        "ds = ds.shuffle(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCKbwbv4nQO1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "439b3453-2b95-4741-d2ec-e1513f20003d"
      },
      "source": [
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([ 73, 116,  32, 105, 115,  32,  97,  32,  98, 101], dtype=int32),\n",
              "  array([116,  32, 105, 115,  32,  97,  32,  98, 101,  97], dtype=int32)),\n",
              " (array([ 97, 110, 100,  32, 104,  97, 118, 101,  32, 102], dtype=int32),\n",
              "  array([110, 100,  32, 104,  97, 118, 101,  32, 102, 117], dtype=int32)),\n",
              " (array([ 32, 114, 105, 103, 104, 116,  63,  32,  10,  76], dtype=int32),\n",
              "  array([114, 105, 103, 104, 116,  63,  32,  10,  76, 101], dtype=int32)),\n",
              " (array([116,  39, 115,  32, 103, 111,  32, 111, 117, 116], dtype=int32),\n",
              "  array([ 39, 115,  32, 103, 111,  32, 111, 117, 116,  32], dtype=int32)),\n",
              " (array([117, 116, 105, 102, 117, 108,  32, 100,  97, 121], dtype=int32),\n",
              "  array([116, 105, 102, 117, 108,  32, 100,  97, 121,  44], dtype=int32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQSlIEp_nbCF"
      },
      "source": [
        "#Split those (input->target) sets into batches, each batch has Batch_size 个 (input->target) sets\n",
        "ds = ds.batch(2, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUjs6XIMn9NE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fe8abc1e-bae9-4e7b-b151-dd1570231c6f"
      },
      "source": [
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([[117, 116, 105, 102, 117, 108,  32, 100,  97, 121],\n",
              "         [116,  39, 115,  32, 103, 111,  32, 111, 117, 116]], dtype=int32),\n",
              "  array([[116, 105, 102, 117, 108,  32, 100,  97, 121,  44],\n",
              "         [ 39, 115,  32, 103, 111,  32, 111, 117, 116,  32]], dtype=int32)),\n",
              " (array([[ 97, 110, 100,  32, 104,  97, 118, 101,  32, 102],\n",
              "         [ 32, 114, 105, 103, 104, 116,  63,  32,  10,  76]], dtype=int32),\n",
              "  array([[110, 100,  32, 104,  97, 118, 101,  32, 102, 117],\n",
              "         [114, 105, 103, 104, 116,  63,  32,  10,  76, 101]], dtype=int32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8QfXI00s6XM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26e28271-7f7d-4f57-83c1-94f6803c3eee"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((2, 10), (2, 10)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmQG5ElupkfD"
      },
      "source": [
        "ds = ds.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tV9GTR1puVp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29b8533e-289d-426a-c2dd-76b58769dff7"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RepeatDataset shapes: ((2, 10), (2, 10)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58nEZN1KDfQl"
      },
      "source": [
        "总结上面的代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPR964wBB30P"
      },
      "source": [
        "#总结以上\n",
        "def input_fn(seq_len=100, batch_size=1024):\n",
        "  with tf.io.gfile.GFile(SHAKESPEARE_TXT,'r') as f:\n",
        "    txt = f.read()\n",
        "  \n",
        "  source = tf.constant(transfor(txt), dtype=tf.int32)\n",
        "\n",
        "  ds = tf.data.Dataset.from_tensor_slices(source)\n",
        "  ds = ds.batch(seq_len+1, drop_remainder=True)\n",
        "\n",
        "  def split_input_target(chunk):\n",
        "    input_txt = chunk[:-1]\n",
        "    output_txt = chunk[1:]\n",
        "    return input_txt, output_txt\n",
        "\n",
        "  SHUFFLE_BUFFER_SIZE = 1000\n",
        "  ds = ds.map(split_input_target)\n",
        "  ds = ds.shuffle(SHUFFLE_BUFFER_SIZE)\n",
        "  ds = ds.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "  return ds.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twf25X3aqIjN"
      },
      "source": [
        "EMBEDDING_DIM = 512\n",
        "#规定input shape is (Batch_size, Seq_len(每句话有几个字母))\n",
        "def lstm_model(seq_len=10, batch_size=None, stateful=True):\n",
        "  source = tf.keras.Input(name='seed', shape=(seq_len,),batch_size=batch_size, dtype=tf.int32)\n",
        "\n",
        "  return source"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBf40OmlvrXd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1701876e-6559-46c7-8667-4ebb76858341"
      },
      "source": [
        "source = lstm_model(10, None, False)\n",
        "source"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'seed:0' shape=(None, 10) dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VF1XaOiwmWf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "993b3b44-e47f-4380-ab7d-e4c775d15414"
      },
      "source": [
        "#Embedding Layer(input_dim= Vocabulary Size, output_dim = Dimension of output, input_len=Sequence_len(一句话有几个字母))\n",
        "#input_len has to be set when connect with Flatten or Dense layer\n",
        "#Input_shape => source (Batch_size, Sequence_len)\n",
        "#把一个字母变成一个shape为(256,)的数组\n",
        "embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "embedding\n",
        "#output_shape => (Batch_size, Sequence_len, output_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_1/Identity:0' shape=(None, 10, 512) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOIkcSD44eP4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57c595e5-ecc0-45e2-82be-e7ed558dfd44"
      },
      "source": [
        "#input_shape (Batch_size=None, TimeSteps/input_len/Sequence_len=10, input_dimension=512)\n",
        "lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=False, return_sequences=True)(embedding)\n",
        "lstm_1\n",
        "#output_shape (Batch_size=None, Timesteps=10, out_dim=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'lstm_2/Identity:0' shape=(None, 10, 512) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUOi1wQL-GiQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95ae40b7-f5e8-4934-91be-3df18fba68ec"
      },
      "source": [
        "#input_shape (Batch_size=None, TimeSteps/input_len/Sequence_len=10, input_dimension=512)\n",
        "lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=False, return_sequences=True)(lstm_1)\n",
        "lstm_2\n",
        "#output_shape (Batch_size=None, Timesteps=10, out_dim=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'lstm_3/Identity:0' shape=(None, 10, 512) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzEDcJVa7lvm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e3e9d24-988f-4ada-dc9e-2df652b6a404"
      },
      "source": [
        "predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256,activation='softmax'))(lstm_2)\n",
        "predicted_char"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'time_distributed_1/Identity:0' shape=(None, 10, 256) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9X6GCWbGaxE"
      },
      "source": [
        "#Model代码总结"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDkF0ev1CqHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e68fe3ee-a1c8-4fb3-f94e-feaa89aba5b2"
      },
      "source": [
        "model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "seed (InputLayer)            [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 10, 512)           131072    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 10, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 10, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 10, 256)           131328    \n",
            "=================================================================\n",
            "Total params: 4,460,800\n",
            "Trainable params: 4,460,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7XrfkorNxp6"
      },
      "source": [
        "#Summary above\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
        "  \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
        "  source = tf.keras.Input(\n",
        "      name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "  lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
        "  lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
        "  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
        "  return tf.keras.Model(inputs=[source], outputs=[predicted_char])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnU_AFwGK9RX"
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-eQHSdgK7q2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "4927c2c4-a68e-4140-b46a-544112b0c4b8"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = lstm_model(seq_len=100, stateful=False)\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy']\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.9.96.90:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.9.96.90:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12779657112255270877)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4157330350771135454)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1717799881030086658)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 15213632275795428761)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7206331319010215850)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12111842701376237562)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12341016240146786796)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5623980512713410053)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1142623924711846462)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 13476729602032272769)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3474514319304415764)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsuA6JP2LFQy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "243dd4d7-35a7-4c96-df63-017ca5363545"
      },
      "source": [
        "model.fit(\n",
        "    input_fn(), #ds中每条都是（input->target)的set\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 3.4938 - sparse_categorical_accuracy: 0.1590\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 3.0443 - sparse_categorical_accuracy: 0.1968\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 2.7753 - sparse_categorical_accuracy: 0.2635\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 2.2097 - sparse_categorical_accuracy: 0.3714\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.7072 - sparse_categorical_accuracy: 0.4936\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.4450 - sparse_categorical_accuracy: 0.5635\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 1.3398 - sparse_categorical_accuracy: 0.5906\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2849 - sparse_categorical_accuracy: 0.6040\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2469 - sparse_categorical_accuracy: 0.6138\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.2200 - sparse_categorical_accuracy: 0.6202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc321bc4f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwj_QuGyNbhD"
      },
      "source": [
        "model.save_weights('/tmp/bard.h5', overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2tsO4KqEOvr"
      },
      "source": [
        "#给要用来预测的话做 5 组不同的预测，即5次预测\n",
        "BATCH_SIZE = 5\n",
        "#每组预测250个字母\n",
        "PREDICT_LEN = 250"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3L2zys3NdZs"
      },
      "source": [
        "#set stateful=True so model's state is kept between batches. \n",
        "#If stateful=False, the model state is reset between each batch\n",
        "#and the model will only be able to use the information from the current batch (a single character) \n",
        "#to make a prediction.\n",
        "\n",
        "#当stateful为True时，必须要set Batch_size\n",
        "#因为我们一个一个字母的feed给model 所以把seq_len设为1\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights('/tmp/bard.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mduPg_K-PbzM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "872c0d20-1d0c-4fdf-f51b-1cae3495ec54"
      },
      "source": [
        "# We seed the model with our initial string, copied BATCH_SIZE times\n",
        "seed_txt = 'Looks it not like the king?  Verily, we must go! '\n",
        "seed = transfor(seed_txt)\n",
        "seed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "       108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "        63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "        32, 109, 117, 115, 116,  32, 103, 111,  33,  32], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJmAUjR9P5GP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "478e971d-8995-4b37-8865-f950a98595ff"
      },
      "source": [
        "#给要用来预测的话加上一个维度（之后好整段repeat5次）\n",
        "seed = np.expand_dims(seed, 0)\n",
        "seed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRcbcD5zFV0x"
      },
      "source": [
        "#seed = np.repeat(seed, 2, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIiz-P-mFg8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "56dea58f-9b93-45de-e0b7-7ba3b5a6364d"
      },
      "source": [
        "#seed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 76,  76, 111, 111, 111, 111, 107, 107, 115, 115,  32,  32, 105,\n",
              "        105, 116, 116,  32,  32, 110, 110, 111, 111, 116, 116,  32,  32,\n",
              "        108, 108, 105, 105, 107, 107, 101, 101,  32,  32, 116, 116, 104,\n",
              "        104, 101, 101,  32,  32, 107, 107, 105, 105, 110, 110, 103, 103,\n",
              "         63,  63,  32,  32,  32,  32,  86,  86, 101, 101, 114, 114, 105,\n",
              "        105, 108, 108, 121, 121,  44,  44,  32,  32, 119, 119, 101, 101,\n",
              "         32,  32, 109, 109, 117, 117, 115, 115, 116, 116,  32,  32, 103,\n",
              "        103, 111, 111,  33,  33,  32,  32]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ALZMbwOEBG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c200c82c-ebe1-4309-8716-8befc838b159"
      },
      "source": [
        "#将整句话复制5遍\n",
        "seed = np.repeat(seed, BATCH_SIZE, axis=0)\n",
        "seed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zz81mwtRBNj"
      },
      "source": [
        "---------------------------\n",
        "testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "682u9t3JPjTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "433cc357-a327-4c28-e760-f016210b9583"
      },
      "source": [
        "len(seed_txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMPScAVWOd6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a0a95efe-8aae-431a-d166-c3d044933393"
      },
      "source": [
        "preds = [seed[:, -1:]]\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[32],\n",
              "        [32],\n",
              "        [32],\n",
              "        [32],\n",
              "        [32]], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IurM0dC4UCAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4a59d12-de8a-424d-9f3d-7da019d30000"
      },
      "source": [
        "preds = seed[0, -1:]\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny6CnN6dRM0R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8f1db538-df33-4c18-b7c2-2dadf5a12117"
      },
      "source": [
        "last_word = predictions[-1]\n",
        "last_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32],\n",
              "       [32],\n",
              "       [32],\n",
              "       [32],\n",
              "       [32]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZd2DBcsRH38"
      },
      "source": [
        "-------------------------------------\n",
        "test end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrI64phaRLqb"
      },
      "source": [
        "prediction_model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6XaRaRDRTQi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3525ab7d-e1bf-4499-d86d-271dba74c5be"
      },
      "source": [
        "#Run the seed forward to prime the state of model\n",
        "for i in range(len(seed_txt)-1):\n",
        "  print(seed[:, i:i+1])\n",
        "  prediction_model.predict(seed[:, i:i+1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[76]\n",
            " [76]\n",
            " [76]\n",
            " [76]\n",
            " [76]]\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n",
            "[[111]\n",
            " [111]\n",
            " [111]\n",
            " [111]\n",
            " [111]]\n",
            "[[111]\n",
            " [111]\n",
            " [111]\n",
            " [111]\n",
            " [111]]\n",
            "[[107]\n",
            " [107]\n",
            " [107]\n",
            " [107]\n",
            " [107]]\n",
            "[[115]\n",
            " [115]\n",
            " [115]\n",
            " [115]\n",
            " [115]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[105]\n",
            " [105]\n",
            " [105]\n",
            " [105]\n",
            " [105]]\n",
            "[[116]\n",
            " [116]\n",
            " [116]\n",
            " [116]\n",
            " [116]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[110]\n",
            " [110]\n",
            " [110]\n",
            " [110]\n",
            " [110]]\n",
            "[[111]\n",
            " [111]\n",
            " [111]\n",
            " [111]\n",
            " [111]]\n",
            "[[116]\n",
            " [116]\n",
            " [116]\n",
            " [116]\n",
            " [116]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[108]\n",
            " [108]\n",
            " [108]\n",
            " [108]\n",
            " [108]]\n",
            "[[105]\n",
            " [105]\n",
            " [105]\n",
            " [105]\n",
            " [105]]\n",
            "[[107]\n",
            " [107]\n",
            " [107]\n",
            " [107]\n",
            " [107]]\n",
            "[[101]\n",
            " [101]\n",
            " [101]\n",
            " [101]\n",
            " [101]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[116]\n",
            " [116]\n",
            " [116]\n",
            " [116]\n",
            " [116]]\n",
            "[[104]\n",
            " [104]\n",
            " [104]\n",
            " [104]\n",
            " [104]]\n",
            "[[101]\n",
            " [101]\n",
            " [101]\n",
            " [101]\n",
            " [101]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[107]\n",
            " [107]\n",
            " [107]\n",
            " [107]\n",
            " [107]]\n",
            "[[105]\n",
            " [105]\n",
            " [105]\n",
            " [105]\n",
            " [105]]\n",
            "[[110]\n",
            " [110]\n",
            " [110]\n",
            " [110]\n",
            " [110]]\n",
            "[[103]\n",
            " [103]\n",
            " [103]\n",
            " [103]\n",
            " [103]]\n",
            "[[63]\n",
            " [63]\n",
            " [63]\n",
            " [63]\n",
            " [63]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[86]\n",
            " [86]\n",
            " [86]\n",
            " [86]\n",
            " [86]]\n",
            "[[101]\n",
            " [101]\n",
            " [101]\n",
            " [101]\n",
            " [101]]\n",
            "[[114]\n",
            " [114]\n",
            " [114]\n",
            " [114]\n",
            " [114]]\n",
            "[[105]\n",
            " [105]\n",
            " [105]\n",
            " [105]\n",
            " [105]]\n",
            "[[108]\n",
            " [108]\n",
            " [108]\n",
            " [108]\n",
            " [108]]\n",
            "[[121]\n",
            " [121]\n",
            " [121]\n",
            " [121]\n",
            " [121]]\n",
            "[[44]\n",
            " [44]\n",
            " [44]\n",
            " [44]\n",
            " [44]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[119]\n",
            " [119]\n",
            " [119]\n",
            " [119]\n",
            " [119]]\n",
            "[[101]\n",
            " [101]\n",
            " [101]\n",
            " [101]\n",
            " [101]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[109]\n",
            " [109]\n",
            " [109]\n",
            " [109]\n",
            " [109]]\n",
            "[[117]\n",
            " [117]\n",
            " [117]\n",
            " [117]\n",
            " [117]]\n",
            "[[115]\n",
            " [115]\n",
            " [115]\n",
            " [115]\n",
            " [115]]\n",
            "[[116]\n",
            " [116]\n",
            " [116]\n",
            " [116]\n",
            " [116]]\n",
            "[[32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]]\n",
            "[[103]\n",
            " [103]\n",
            " [103]\n",
            " [103]\n",
            " [103]]\n",
            "[[111]\n",
            " [111]\n",
            " [111]\n",
            " [111]\n",
            " [111]]\n",
            "[[33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSI5MhjZSK36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1a3341f4-c45d-44b4-d0e3-b86adafa765e"
      },
      "source": [
        "# Now we can accumulate predictions!\n",
        "predictions = [seed[:, -1:]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[32],\n",
              "        [32],\n",
              "        [32],\n",
              "        [32],\n",
              "        [32]], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdaUz7AVUqwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22dd8a9b-60d6-4faa-ec5c-d4138f65d20e"
      },
      "source": [
        "test = np.array([[[2,3]],[[2,3]],[[2,3]]])\n",
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG3Qw0OZbywy"
      },
      "source": [
        "________________________\n",
        "解释用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3yrr8SlSaaV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "bfe5cba2-ae97-401d-d2de-b6c8f5236e75"
      },
      "source": [
        "for i in range(1):\n",
        "  #batch_size 设为 5,即输入进去每组5个，每个为当前predictions中的最后1个字母\n",
        "  #即shape为（batch_size=5, timeSteps/seq_len=1, input_dim/Vocabularies=256)\n",
        "  last_word = predictions[-1]\n",
        "  #输出的结果的shape为（batch_size=5, timeSteps/seq_len=1, input_dim/Vocabularies=256)\n",
        "  next_probits = prediction_model.predict(x=last_word)\n",
        "  print(next_probits)\n",
        "  #batch_size的5个都保留，因为每个seq_len/timeSteps中只有1个字母，即为第0项\n",
        "  #每个seq_len有256个维度（即字典内共256个字母）\n",
        "  next_probits = next_probits[:, 0, :]\n",
        "  print(next_probits)\n",
        "\n",
        "  #用预测出的概率，算出batch中的5个字母分别预测到的是什么字母\n",
        "  next_idx = [         #a=256代表np.arange(256)->[0,1,2,3,...,255]\n",
        "      np.random.choice(a=256, p=next_probits[i]) #p表示数组a中对应每个位置上可能被选中的概率\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        "  print(predictions)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "   2.3955368e-10 3.7252418e-10]]\n",
            "\n",
            " [[3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "   2.3955368e-10 3.7252418e-10]]\n",
            "\n",
            " [[3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "   2.3955368e-10 3.7252418e-10]]\n",
            "\n",
            " [[3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "   2.3955368e-10 3.7252418e-10]]\n",
            "\n",
            " [[3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "   2.3955368e-10 3.7252418e-10]]]\n",
            "[[3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "  2.3955368e-10 3.7252418e-10]\n",
            " [3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "  2.3955368e-10 3.7252418e-10]\n",
            " [3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "  2.3955368e-10 3.7252418e-10]\n",
            " [3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "  2.3955368e-10 3.7252418e-10]\n",
            " [3.3767023e-10 3.0895714e-10 2.5281263e-10 ... 4.2209461e-10\n",
            "  2.3955368e-10 3.7252418e-10]]\n",
            "[array([[32],\n",
            "       [32],\n",
            "       [32],\n",
            "       [32],\n",
            "       [32]], dtype=int32), array([32, 32, 32, 32, 32], dtype=int32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JL-dS1gb5i9"
      },
      "source": [
        "______________\n",
        "解释结束"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQN-8Wk9b-O5"
      },
      "source": [
        "for i in range(PREDICT_LEN):\n",
        "  #batch_size 设为 5,即输入进去每组5个，每个为当前predictions中的最后1个字母\n",
        "  #即shape为（batch_size=5, timeSteps/seq_len=1, input_dim/Vocabularies=256)\n",
        "  last_word = predictions[-1]\n",
        "  #输出的结果的shape为（batch_size=5, timeSteps/seq_len=1, input_dim/Vocabularies=256)\n",
        "  next_probits = prediction_model.predict(x=last_word)\n",
        "  #batch_size的5个都保留，因为每个seq_len/timeSteps中只有1个字母，即为第0项\n",
        "  #每个seq_len有256个维度（即字典内共256个字母）\n",
        "  next_probits = next_probits[:, 0, :]\n",
        "\n",
        "  #用预测出的概率，算出batch中的5个字母分别预测到的是什么字母\n",
        "  next_idx = [         #a=256代表np.arange(256)->[0,1,2,3,...,255]\n",
        "      np.random.choice(a=256, p=next_probits[i]) #p表示数组a中对应每个位置上可能被选中的概率\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PYqsNA3cIZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "131d2386-118f-4f9e-f6d9-ef47960dd48e"
      },
      "source": [
        "print(predictions[:3])\n",
        "#predictions 中 有PREDICT_LEN=256个array，对应往下预测256个字母\n",
        "#每个array中有batch_size=5个字母，对应5组不同的预测结果\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[32],\n",
            "       [32],\n",
            "       [32],\n",
            "       [32],\n",
            "       [32]], dtype=int32), array([32, 32, 32, 32, 32], dtype=int32), array([32, 32, 32, 32, 32], dtype=int32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPcuZue9c2B8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "584d1349-53fc-43a5-bc49-63da1578fd11"
      },
      "source": [
        "for i in range(BATCH_SIZE):\n",
        "  print('Prediction %d\\n\\n' % i)\n",
        "  #将predictions中256个字母组合起来\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  #将unicode转换为char\n",
        "  generate = ''.join([chr(c) for c in p])\n",
        "  print(generate)\n",
        "  print('---------------------------')\n",
        "  #生成的字母必须为PREDICT_LEN个\n",
        "  assert len(generate) == PREDICT_LEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction 0\n",
            "\n",
            "\n",
            "                             [Tragsting i th arm upon the patland.]\r\n",
            "\r\n",
            "\r\n",
            "                   SCENE IV. Padua.\r\n",
            "\r\n",
            "\r\n",
            "           DOLABELLA, Julia but NURVINGMAN a bapher of OLIFF]\r\n",
            "\r\n",
            "That I said, a modesty acquaintance in a thought upon my particular for\n",
            "---------------------------\n",
            "Prediction 1\n",
            "\n",
            "\n",
            "                                Exeunt\r\n",
            "\r\n",
            "          336\r\n",
            "\r\n",
            "   And here Priam and 'These arratial come\r\n",
            "Most, an accounted my father, but hone\r\n",
            "Most immortal furwearing think our \r\n",
            "To practice the scald of Hamlet at a jest, danger. A better than us.\r\n",
            "\n",
            "---------------------------\n",
            "Prediction 2\n",
            "\n",
            "\n",
            "                    ordement torture\r\n",
            "    The full lamp but to be\r\n",
            "    That the crow-trees a brace.\r\n",
            "  VILUMNIA. Ay, for thy sisters, but revelled-time were heaven; never that he is; what\r\n",
            "    shrubs to hear at home.\r\n",
            "    As whom what I do bed it opp\n",
            "---------------------------\n",
            "Prediction 3\n",
            "\n",
            "\n",
            "                   13290\r\n",
            "\r\n",
            "\r\n",
            "An if thy villaried dishonour hath call'd thy praise,\r\n",
            "Why do the sway to pry our power,\r\n",
            "Horatio in the like precedency when the last pity shall make free\r\n",
            "That he were cleadly, and all artal it wack about my breath to \n",
            "---------------------------\n",
            "Prediction 4\n",
            "\n",
            "\n",
            "                  Exit HASTINGS\r\n",
            "  ENOBARBUS. I have been seizure.\r\n",
            "    Pray you leave to my exercision father\r\n",
            "    The morn, niece aard a most eye.\r\n",
            "    Sting?\r\n",
            "  ROSALIND. No, uncle, fly thou dar'st.\r\n",
            "  ISANIO.\r\n",
            "      You hang your Grace was a sink\n",
            "---------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}